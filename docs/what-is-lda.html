<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>LDA Tutorial</title>
  <meta name="description" content="LDA Tutorial">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="LDA Tutorial" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="LDA Tutorial" />
  <meta name="twitter:site" content="@devlintufts" />
  
  

<meta name="author" content="Chris Tufts">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="package-references.html">
<link rel="next" href="parameter-estimation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i>Background</a></li>
<li class="chapter" data-level="" data-path="layout-of-book.html"><a href="layout-of-book.html"><i class="fa fa-check"></i>Layout of Book</a></li>
<li class="chapter" data-level="" data-path="package-references.html"><a href="package-references.html"><i class="fa fa-check"></i>Package References</a></li>
<li class="chapter" data-level="1" data-path="what-is-lda.html"><a href="what-is-lda.html"><i class="fa fa-check"></i><b>1</b> What is LDA?</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-lda.html"><a href="what-is-lda.html#animal-generator"><i class="fa fa-check"></i><b>1.1</b> Animal Generator</a><ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-lda.html"><a href="what-is-lda.html#generating-the-mixtures"><i class="fa fa-check"></i><b>1.1.1</b> Generating the Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-lda.html"><a href="what-is-lda.html#inference"><i class="fa fa-check"></i><b>1.2</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>2</b> Parameter Estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="parameter-estimation.html"><a href="parameter-estimation.html#distributions"><i class="fa fa-check"></i><b>2.1</b> Distributions</a><ul>
<li class="chapter" data-level="2.1.1" data-path="parameter-estimation.html"><a href="parameter-estimation.html#bernoulli"><i class="fa fa-check"></i><b>2.1.1</b> Bernoulli</a></li>
<li class="chapter" data-level="2.1.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html#beta-distribution"><i class="fa fa-check"></i><b>2.1.2</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html#inference-the-building-blocks"><i class="fa fa-check"></i><b>2.2</b> Inference: The Building Blocks</a></li>
<li class="chapter" data-level="2.3" data-path="parameter-estimation.html"><a href="parameter-estimation.html#maximum-likelihood"><i class="fa fa-check"></i><b>2.3</b> Maximum Likelihood</a></li>
<li class="chapter" data-level="2.4" data-path="parameter-estimation.html"><a href="parameter-estimation.html#maximum-a-posteriori"><i class="fa fa-check"></i><b>2.4</b> Maximum a Posteriori</a></li>
<li class="chapter" data-level="2.5" data-path="parameter-estimation.html"><a href="parameter-estimation.html#bayesian-inference"><i class="fa fa-check"></i><b>2.5</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="2.5.1" data-path="parameter-estimation.html"><a href="parameter-estimation.html#analytical-solution"><i class="fa fa-check"></i><b>2.5.1</b> Analytical Solution</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="parameter-estimation.html"><a href="parameter-estimation.html#gibbs-sampling"><i class="fa fa-check"></i><b>2.6</b> Gibbs Sampling</a><ul>
<li class="chapter" data-level="2.6.1" data-path="parameter-estimation.html"><a href="parameter-estimation.html#the-issue-of-intractability"><i class="fa fa-check"></i><b>2.6.1</b> The Issue of Intractability</a></li>
<li class="chapter" data-level="2.6.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html#a-tale-of-two-mcs"><i class="fa fa-check"></i><b>2.6.2</b> A Tale of Two MCâ€™s</a></li>
<li class="chapter" data-level="2.6.3" data-path="parameter-estimation.html"><a href="parameter-estimation.html#conjugate-distributions-and-priors"><i class="fa fa-check"></i><b>2.6.3</b> Conjugate Distributions and Priors</a></li>
<li class="chapter" data-level="2.6.4" data-path="parameter-estimation.html"><a href="parameter-estimation.html#gibbs-sampling-1"><i class="fa fa-check"></i><b>2.6.4</b> Gibbs Sampling</a></li>
<li class="chapter" data-level="2.6.5" data-path="parameter-estimation.html"><a href="parameter-estimation.html#bias-of-two-coins"><i class="fa fa-check"></i><b>2.6.5</b> Bias of Two Coins</a></li>
<li class="chapter" data-level="2.6.6" data-path="parameter-estimation.html"><a href="parameter-estimation.html#change-point-example"><i class="fa fa-check"></i><b>2.6.6</b> Change Point Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multinomial-distribution.html"><a href="multinomial-distribution.html"><i class="fa fa-check"></i><b>3</b> Multinomial Distribution</a><ul>
<li class="chapter" data-level="3.1" data-path="multinomial-distribution.html"><a href="multinomial-distribution.html#comparison-of-dice-vs.words"><i class="fa fa-check"></i><b>3.1</b> Comparison of Dice vs.Â Words</a></li>
<li class="chapter" data-level="3.2" data-path="multinomial-distribution.html"><a href="multinomial-distribution.html#how-multinomial-and-bernoulli-relate"><i class="fa fa-check"></i><b>3.2</b> How Multinomial and Bernoulli Relate</a></li>
<li class="chapter" data-level="3.3" data-path="multinomial-distribution.html"><a href="multinomial-distribution.html#conjugate-prior-dirichlet"><i class="fa fa-check"></i><b>3.3</b> Conjugate Prior: Dirichlet</a></li>
<li class="chapter" data-level="3.4" data-path="multinomial-distribution.html"><a href="multinomial-distribution.html#gibbs-sampling---multinomial-dirichlet"><i class="fa fa-check"></i><b>3.4</b> Gibbs Sampling - Multinomial &amp; Dirichlet</a><ul>
<li class="chapter" data-level="3.4.1" data-path="multinomial-distribution.html"><a href="multinomial-distribution.html#derivation-of-gibbs-sampling-solution-of-word-distribution-single-doc"><i class="fa fa-check"></i><b>3.4.1</b> Derivation of Gibbs Sampling Solution of Word Distribution (Single Doc)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="word-representations.html"><a href="word-representations.html"><i class="fa fa-check"></i><b>4</b> Word Representations</a><ul>
<li class="chapter" data-level="4.1" data-path="word-representations.html"><a href="word-representations.html#bag-of-words"><i class="fa fa-check"></i><b>4.1</b> Bag of Words</a></li>
<li class="chapter" data-level="4.2" data-path="word-representations.html"><a href="word-representations.html#word-counts"><i class="fa fa-check"></i><b>4.2</b> Word Counts</a></li>
<li class="chapter" data-level="4.3" data-path="word-representations.html"><a href="word-representations.html#plug-and-play-lda"><i class="fa fa-check"></i><b>4.3</b> Plug and Play LDA</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lda-as-a-generative-model.html"><a href="lda-as-a-generative-model.html"><i class="fa fa-check"></i><b>5</b> LDA as a Generative Model</a><ul>
<li class="chapter" data-level="5.1" data-path="lda-as-a-generative-model.html"><a href="lda-as-a-generative-model.html#general-terminology"><i class="fa fa-check"></i><b>5.1</b> General Terminology</a><ul>
<li class="chapter" data-level="5.1.1" data-path="lda-as-a-generative-model.html"><a href="lda-as-a-generative-model.html#selecting-parameters"><i class="fa fa-check"></i><b>5.1.1</b> Selecting Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="lda-as-a-generative-model.html"><a href="lda-as-a-generative-model.html#generative-model"><i class="fa fa-check"></i><b>5.2</b> Generative Model</a><ul>
<li class="chapter" data-level="5.2.1" data-path="lda-as-a-generative-model.html"><a href="lda-as-a-generative-model.html#generating-documents"><i class="fa fa-check"></i><b>5.2.1</b> Generating Documents</a></li>
<li class="chapter" data-level="5.2.2" data-path="lda-as-a-generative-model.html"><a href="lda-as-a-generative-model.html#lda-generative-model"><i class="fa fa-check"></i><b>5.2.2</b> LDA Generative Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lda-inference.html"><a href="lda-inference.html"><i class="fa fa-check"></i><b>6</b> LDA Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="lda-inference.html"><a href="lda-inference.html#general-overview"><i class="fa fa-check"></i><b>6.1</b> General Overview</a></li>
<li class="chapter" data-level="6.2" data-path="lda-inference.html"><a href="lda-inference.html#mathematical-derivations-for-inference"><i class="fa fa-check"></i><b>6.2</b> Mathematical Derivations for Inference</a></li>
<li class="chapter" data-level="6.3" data-path="lda-inference.html"><a href="lda-inference.html#animal-farm---code-example"><i class="fa fa-check"></i><b>6.3</b> Animal Farm - Code Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">LDA Tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="what-is-lda" class="section level1">
<h1><span class="header-section-number">1</span> What is LDA?</h1>
<p>Latent Dirichlet Allocation (LDA) is a generative probablistic model for collections of discrete data developed by Blei, Ng, and Jordan. <span class="citation">(Blei, Ng, and Jordan <a href="references.html#ref-blei2003latent">2003</a>)</span> One of the most common uses of LDA is for modeling collections of text. LDA is often used for what is known as topic modeling.</p>
<p>A topic is a probability distribution over words.<span class="citation">(Steyvers and Griffiths <a href="references.html#ref-steyvers2007probabilistic">2007</a>)</span> Imagine you have a bag that has a bunch of little squares in it with a word printed on each (similar to the game Scrabble, but words instead of letters). Any word not in the bag has a probability of being drawn equal to zero. However all other words in the bag have a probability greater than zero. Letâ€™s say we have 2 chips with the word â€˜philadelphiaâ€™ and 1 with the word â€˜eaglesâ€™ on it. We would say you have a 1/3 chance of drawing â€˜eaglesâ€™, 2/3 chance of drawing â€˜philadelphiaâ€™, and 0 for any other word. This is effectively what a topic is; it provides us with the probabilities of a set of words for the given topic.</p>
<p>â€”â€”â€”â€”â€”â€“IMAGE PLACE HOLDER - different bags of topicsâ€”â€”â€”â€”â€”â€”â€”â€”-</p>
<p>The general idea of LDA is that each document is generated from a mixture of topics and each of those topics is a mixture of words. This can be used as a mechanism for generating new documents, i.e.Â we know the topics a priori, or for inferring topics present in a set of documents we already have.</p>
<p>In regards to the model name, you can think of it as follows:</p>
<ul>
<li><b>Latent</b>: Topic structures in a document are â€˜latentâ€™ meaning they are hidden structures in the text.</li>
<li><b>Dirichlet</b>: The Dirichlet distribution determines the mixture proportions of the topics in the documents and the words in each topic.</li>
<li><b>Allocation</b>: Allocation of words to a given topic.</li>
</ul>
<p>To review: we have latent structures in a corpus (topics), with topic distributions in each document and word distributions in each topic based on the Dirichlet distribution, to allocate words to a given topic and topics to a given document.</p>
<p>I realize many reading this may be unfamiliar with some of the terminology and distributions mentioned in the opening paragraphs. Please keep reading, all the nuts an bolts will be addressed in the following chapters, but to help get an understanding of what LDA is and why it is useful, I will offer a quick example and we will get to the math and technical concepts in the following chapters.</p>
<div id="animal-generator" class="section level2">
<h2><span class="header-section-number">1.1</span> Animal Generator</h2>
<p>The majority of this book is about words, topics, and documents, but lets start with something a bit different: animals and where they live. One of the ways you can classify animals is by where they spend the majority of their time - land, air, sea. Obviously there are some animals that only dwell in one place; a cow only lives on land and a fish only lives in the sea. However, there are other animals, such as some birds, that split their time between land, sea, and air.</p>
<p>You are probably asking yourself â€˜where is he going with this?â€™. We can think of land, air, and sea as topics that contain a distribution of animals. In this case we can equate animals with words. For example, on land I am much more likely to see a cow than a whale, but in the sea it would be the reverse. If I quantify these probabilities into a distribution over all the animals (<i>words</i>) for each type of habitat (land,sea, air - <i>topics</i>) I can use them to generate sets of animals (<i>words</i>) to populate a given location (<i>document</i>) which may contain a mix of land, sea, and air (<i>topics</i>).</p>
<p>So letâ€™s move on to generating a specific location. We know that different locations will vary in terms of which habitats are present. For example, a beach contains land, sea, and air, but some areas inland may only contain air and land like a desert. We can define the mixture of these types of habitats in each location. For example, a beach is 1/3 land, 1/3 sea, and 1/3 air. We can think of the beach as a single document. To review: a given location (<em>document</em>) contains a mixture of land, air, and sea (<em>topics</em>) and each of those contain different mixtures of animals (<em>words</em>).</p>
<p>Letâ€™s work through some examples using our animals and habitats. The examples provided in this chapter are oversimplified so that we can get a general idea how LDA works.</p>
<p>Weâ€™ll start by generating our beach location with 1/3 land animals, 1/3 sea animals, and 1/3 air animals. Below you can see our collection of animals and their probability in each topic. Note that some animals have zero probabilities in a given topic, i.e.Â a cow is never in the ocean, where some have higher probabilities than others; a crab is in the sea sometimes, but a fish is always in the sea. You may notice that there is only 1 animal in the air category. There are several birds, but only 1 of them is cabable of flight in our vocabulary.</p>
<p>(NOTE: These are the probability of a word <b>given</b> the topic and therefore the probabilities of each habitat (<em>column</em>) sum to 1.)</p>
<table>
<caption><span id="tab:animalVocab">Table 1.1: </span>Animal Distributions in Each Habitat</caption>
<thead>
<tr class="header">
<th align="left">vocab</th>
<th align="right">land</th>
<th align="right">sea</th>
<th align="right">air</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ğŸ‹</td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ³</td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸŸ</td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ </td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸ™</td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ¦€</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸŠ</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ¢</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸ</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ“</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸ¦ƒ</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ¦</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">ğŸ§</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ¿</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸ˜</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸ‚</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">ğŸ‘</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ğŸª</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>To generate a beach (<i>document</i>) based off the description we would use those probabilities in a straightforward manner:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">words_per_topic &lt;-<span class="st"> </span><span class="dv">3</span>
equal_doc &lt;-<span class="st"> </span><span class="kw">c</span>(vocab[<span class="kw">sample.int</span>(<span class="kw">length</span>(vocab),words_per_topic, <span class="dt">prob=</span>phi_ds$land, <span class="dt">replace =</span> T)],
               vocab[<span class="kw">sample.int</span>(<span class="kw">length</span>(vocab),words_per_topic, <span class="dt">prob=</span>phi_ds$sea, <span class="dt">replace =</span> T)],
               vocab[<span class="kw">sample.int</span>(<span class="kw">length</span>(vocab),words_per_topic, <span class="dt">prob=</span>phi_ds$air, <span class="dt">replace =</span> T)])
<span class="kw">cat</span>(equal_doc)</code></pre></div>
<pre><code>## ğŸ˜ ğŸ‚ ğŸª ğŸ§ ğŸ§ ğŸ™ ğŸ¦ ğŸ¦ ğŸ¦</code></pre>
<p>NOTE: In the above example the topic mixtures are static and equal, so each habitat (<i>topic</i>) contributes 3 animals to the beach.</p>
<p>Before proceeding, I want to take a moment to give recognition to Tim Hopper for his presentation utilizing emoji to shed some light on how generative LDA works <span class="citation">(Hopper <a href="references.html#ref-HopperTopicModels">2016</a>)</span>.</p>
<p>Ok, now letâ€™s make an ocean setting. In the case of the ocean we only have sea and air present, so our topic distribution in the document would be 50% sea, 50% air, and 0% land.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">words_per_topic &lt;-<span class="st"> </span><span class="dv">3</span>
ocean_doc &lt;-<span class="st"> </span><span class="kw">c</span>(vocab[<span class="kw">sample.int</span>(<span class="kw">length</span>(vocab),words_per_topic, <span class="dt">prob=</span>phi_ds$sea, <span class="dt">replace =</span> T)],
               vocab[<span class="kw">sample.int</span>(<span class="kw">length</span>(vocab),words_per_topic, <span class="dt">prob=</span>phi_ds$air, <span class="dt">replace =</span> T)])
<span class="kw">cat</span>(ocean_doc)</code></pre></div>
<pre><code>## ğŸ‹ ğŸ³ ğŸ¢ ğŸ¦ ğŸ¦ ğŸ¦</code></pre>
<p>NOTE: In the example above only the air and land contribute to the ocean location. Therefore they both contribute an equal number of animals to the location.</p>
<div id="generating-the-mixtures" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Generating the Mixtures</h3>
<p>It is important to note the examples above use static word and topic mixtures that were predetermined, but these mixtures could just as easily be created by sampling from a Dirichlet distribution. This is an important distinction to make as it is the foundation of how we can use LDA to infer topic structures in our documents. The Dirichlet distribution and itâ€™s role in LDA is discussed in detail in the coming chapters.</p>
</div>
</div>
<div id="inference" class="section level2">
<h2><span class="header-section-number">1.2</span> Inference</h2>
<p>We have seen that we can generate collections of animals that are representative of the given location. What if we have thousands of locations and we want to know the mixture of land, air, and sea that are present? And what if we had no idea where each animal spends its time? LDA allows us to infer both of these peices of information. Similar to the locations (<i>documents</i>) generated above, I will create 100 random documents with varying length and various habitat mixtures.</p>
<table>
<caption><span id="tab:introGenerate">Table 1.2: </span>Animals at the First Two Locations</caption>
<thead>
<tr class="header">
<th align="right">Document</th>
<th align="left">Animals</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">ğŸª ğŸ˜ ğŸª ğŸ˜ ğŸ¦ ğŸ“ ğŸª ğŸª ğŸ ğŸª ğŸ§ ğŸ¦€ ğŸ¦€ ğŸª ğŸ“ ğŸ ğŸ˜ ğŸ“ ğŸ ğŸ¿ ğŸ§ ğŸ¢ ğŸ§ ğŸ¦ƒ ğŸ¦ƒ ğŸ§ ğŸ¦ ğŸ‘ ğŸ‘ ğŸŠ ğŸ³ ğŸ¦€ ğŸ¦€ ğŸ¿ ğŸ¢ ğŸ¢ ğŸ¿ ğŸ“ ğŸª ğŸŠ ğŸ˜ ğŸ¦ ğŸª ğŸ‚ ğŸ ğŸ“ ğŸ ğŸ“ ğŸ¦ ğŸ ğŸ¦ƒ ğŸ¦ ğŸª ğŸ ğŸ¿ ğŸ¦ ğŸ¦ ğŸ‚ ğŸ¿ ğŸ ğŸ‚ ğŸ¿ ğŸ¦ ğŸ¦ ğŸ‘ ğŸ‚ ğŸ“ ğŸ“ ğŸ§ ğŸ‘ ğŸ¦ ğŸª ğŸ¦ ğŸ§ ğŸ¿ ğŸª ğŸ¦ ğŸ¢ ğŸ¦ƒ ğŸ¿ ğŸ¦ƒ ğŸ¦ ğŸ‘ ğŸŠ ğŸ¦ƒ ğŸª ğŸ¦ƒ ğŸ“ ğŸ‚ ğŸŠ ğŸŠ ğŸ‚ ğŸ¦ƒ</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">ğŸ™ ğŸ‚ ğŸ¦ ğŸ¦ ğŸ“ ğŸ§ ğŸª ğŸ™ ğŸ§ ğŸ™ ğŸª ğŸ˜ ğŸ‹ ğŸ‚ ğŸ¦ ğŸ§ ğŸ¦ ğŸ™ ğŸ¦ ğŸ³ ğŸŸ ğŸŠ ğŸŸ ğŸ¢ ğŸ  ğŸ  ğŸª ğŸ¢ ğŸ¦ ğŸ˜ ğŸ ğŸ³ ğŸ¦ƒ ğŸŸ ğŸ™ ğŸ¦€ ğŸŠ ğŸ³ ğŸª ğŸ  ğŸ§ ğŸ¢ ğŸ¢ ğŸ¦ ğŸ ğŸ§ ğŸ¿ ğŸ¢ ğŸª ğŸ¢ ğŸ§ ğŸ“ ğŸ‘ ğŸ³ ğŸ§ ğŸ ğŸŠ ğŸ‚ ğŸ¦ƒ ğŸ‹ ğŸª ğŸ“ ğŸ¿ ğŸŸ ğŸ™ ğŸ‹ ğŸ¦€ ğŸ‚ ğŸ¦ ğŸ³ ğŸ¢ ğŸŸ ğŸ¦ ğŸ˜ ğŸŠ ğŸ“ ğŸ“ ğŸ§ ğŸŠ ğŸ¢ ğŸª ğŸ“ ğŸŠ ğŸ¢ ğŸ‘ ğŸ¢ ğŸ™ ğŸŠ ğŸ¢ ğŸ§ ğŸª</td>
</tr>
</tbody>
</table>
<p>The topic word distributions shown in Table 1.1 were used to generate our sample documents. The true habitat (<i>topic</i>) mixtures used to generate the first couple of documents are shown in Table 1.3:</p>
<table>
<caption><span id="tab:unnamed-chunk-4">Table 1.3: </span>Distribution of Habitats in the First Two Locations</caption>
<thead>
<tr class="header">
<th align="right">Document</th>
<th align="right">air</th>
<th align="right">land</th>
<th align="right">sea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.09</td>
<td align="right">0.90</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.09</td>
<td align="right">0.51</td>
<td align="right">0.39</td>
</tr>
</tbody>
</table>
<p>With the help of LDA we can go through all of our documents and estimate the topic/word (<em>habitat/animal</em>) distributions and the topic/document (<em>habitat/location</em>) distributions.</p>
<p>The true and estimated topic word distributions are shown in Table 1.4.</p>
<table>
<caption><span id="tab:unnamed-chunk-5">Table 1.4: </span>True and Estimated Word Distribution for Each Topic</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">air estimated</th>
<th align="right">air</th>
<th align="right">land estimated</th>
<th align="right">land</th>
<th align="right">sea estimated</th>
<th align="right">sea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ğŸ‹</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.11</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td>ğŸ³</td>
<td align="right">0.01</td>
<td align="right">0</td>
<td align="right">0.01</td>
<td align="right">0.00</td>
<td align="right">0.10</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td>ğŸŸ</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.11</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td>ğŸ </td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td>ğŸ™</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.12</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td>ğŸ¦€</td>
<td align="right">0.01</td>
<td align="right">0</td>
<td align="right">0.04</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td>ğŸŠ</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.05</td>
<td align="right">0.05</td>
<td align="right">0.07</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>ğŸ¢</td>
<td align="right">0.01</td>
<td align="right">0</td>
<td align="right">0.05</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td>ğŸ</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.06</td>
<td align="right">0.05</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>ğŸ“</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.10</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>ğŸ¦ƒ</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.10</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>ğŸ¦</td>
<td align="right">0.95</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.05</td>
<td align="right">0.11</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td>ğŸ§</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.05</td>
<td align="right">0.05</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>ğŸ¿</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.10</td>
<td align="right">0.10</td>
<td align="right">0.01</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>ğŸ˜</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.10</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>ğŸ‚</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.10</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>ğŸ‘</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.10</td>
<td align="right">0.10</td>
<td align="right">0.01</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>ğŸª</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0.11</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
</tbody>
</table>
<p>The document topic mixtures and the estimated mixtures are shown below for the first 5 documents:</p>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 1.5: </span>The Estimated Topic Distributions for the First 5 Documents</caption>
<thead>
<tr class="header">
<th align="right">Location</th>
<th align="right">air estimated</th>
<th align="right">air</th>
<th align="right">land estimated</th>
<th align="right">land</th>
<th align="right">sea estimated</th>
<th align="right">sea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.09</td>
<td align="right">0.09</td>
<td align="right">0.90</td>
<td align="right">0.90</td>
<td align="right">0.01</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.05</td>
<td align="right">0.09</td>
<td align="right">0.46</td>
<td align="right">0.51</td>
<td align="right">0.48</td>
<td align="right">0.39</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.41</td>
<td align="right">0.36</td>
<td align="right">0.54</td>
<td align="right">0.64</td>
<td align="right">0.05</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.53</td>
<td align="right">0.50</td>
<td align="right">0.45</td>
<td align="right">0.48</td>
<td align="right">0.02</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.47</td>
<td align="right">0.41</td>
<td align="right">0.25</td>
<td align="right">0.40</td>
<td align="right">0.27</td>
<td align="right">0.19</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0.03</td>
<td align="right">0.02</td>
<td align="right">0.35</td>
<td align="right">0.38</td>
<td align="right">0.62</td>
<td align="right">0.59</td>
</tr>
</tbody>
</table>
<p>The results of our estimations of both the word topic distributions and the document topic distributions have some variation from the true distributions used to generate the documents. The cosine similarity between the estimated and true topic proportions in each document are shown below.</p>
<table>
<caption><span id="tab:cosineDistanceDocTop">Table 1.6: </span>Cosine Similarity between Estimated Document Topic Distributions and Real Distributions</caption>
<thead>
<tr class="header">
<th align="left">air</th>
<th align="left">land</th>
<th align="left">sea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.99</td>
<td align="left">0.99</td>
<td align="left">0.99</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:cosineDistanceTermTop">Table 1.7: </span>Cosine Similarity between Estimated Topic Word Distributions and Real Distributions</caption>
<thead>
<tr class="header">
<th align="left">air</th>
<th align="left">land</th>
<th align="left">sea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1.00</td>
<td align="left">0.99</td>
<td align="left">0.98</td>
</tr>
</tbody>
</table>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="package-references.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="parameter-estimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
